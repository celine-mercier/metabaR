---
title: "Let's MetabaR-F!"
author: "Boyer F., Donald J., Lionnet C., Mercier C., Murienne J., Zinger L."
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

*MetabaR-F* is an R package which supports the importing, handling and postprocessing of metabarcoding data following its initial processing through bioinformatic pipelines. It provides functions to reveal and filter common molecular artifacts produced during the experimental workflow. 

Due to its simple structure, *MetabaR-F* can easily be used in combination with other R packages commonly used for ecological analysis (*vegan*, *ade4*, *ape*, *picante*, etc.). In addition, it provides flexible graphical systems using *ggplot2* to vizualize data from both an ecological and experimental perspective.

## Dependencies and Installation

The philosophy of MetabaR-F is to rely on basic R functions and data structures so as to maximize fexibility and transposability across other packages. It relies on a minimal number of essential R packages :    

- *ggplot2* and *cowplot* for vizualization purposes
- *reshape2* for data manipulation purposes   
- *vegan* for basic data analyses   
- *seqinr* for handling sequence data       
- <span style="color:red">... more?</span>


To install *MetabaR-F*, use : 

```{r install, eval=FALSE}
install.packages("devtools")
devtools::install_github("metabaRfactory/metabaRffe")
```


And then load the package   
```{r loadpackage}
library(metabaRffe) # modify the name once we'll all agree on that
```


## Package overview

<span style="color:red">Temporary --- include class of each object `reads`, `motus`, `pcrs`, `samples`(data.frame, matrix, list)</span>   
![MetabarF over](../metabaRF_overview.png){width=90%}

### Data format and structure

The basic dataformat used in *MetabaR-F* is a `metabarlist`, consisting of a list of four tables:   

- `reads`: a `matrix` consisting of PCRs as rows, and molecular operational taxonomic units (MOTUs) as columns. The number of reads for MOTUs are given in each cell, with 0 corresponding to no reads.   

- `motus`: a `data.frame` where MOTUs are listed as rows, and their attributes as columns. Examples of attributes include taxonomic information, but could also include any information collected during bioinformatic analysis. A mandatory field in this table is "sequence", i.e. the DNA sequence representative of the MOTU.    

- `pcrs`: a `data.frame` consisting of PCRs as rows, and PCR attributes as columns. Mandatory fields are (i) "sample_id", i.e. the biological sample origin for the PCR, (ii) "type" (sample vs. control), and (iii) "control_type" (either `NA` for samples ,"extraction" for DNA extraction negative controls, "pcr" for PCR negative controls, "sequencing" for sequencing negative controls (e.g. unused tag combinations), "positive" for DNA extraction/PCR positive controls). This table can also include information related to the PCR design, such as the tag combinations, the primers used, the well and plate of each PCR, etc.   

- `samples`: a `data.frame` consisting of biological samples as rows, and their information as columns. Information could reprent for example geographic coordinates, abiotic parameters, etc. This table does not include information on the DNA metabarcoding experimental controls, which can only be found in `pcrs`.


### Function Types 

*MetabaR-F* provides a range of function types:

- Import formating functions to import DNA metabarcoding data from common bioinformatic pipelines (OBITools, <span style="color:red">more to come</span>)
- Functions for data curation that are absent from most bioinformatic pipelines (e.g. detecting and tagging potential molecular artifacts such as contaminants, dysfynctional PCRs, etc.)    
- Functions for visualizing the data under both ecological (e.g. type of samples) and experimental (e.g. type of controls, distribution across the PCR plate design) perspectives.
- Functions to manipulate the `metabarlist` object
- <span style="color:red">Blablabla</span>


### Example dataset

An example data set is provided to demonstrate how the package can be used to assess its methodological and ecological implications.  

facilitate reproducible examples and further developments.
- <span style="color:red">WHAT IS MEANT BY FURTHER DEVELOPMENTS??</span>

The `soil_euk` dataset is a `metabarlist`. The data were obtained from an environmental DNA [eDNA] metabarcoding experiment aiming to assess the diversity of soil eukaryotes in French Guiana in two sites corresponding to two contrasting habitats:    
- Mana, a site located in a white sand forest, characterized by highly oligotrophic soils and tree species adapted to the harsh local conditions.
- Petit Plateau, a site located in the pristine rainforest of the Nouragues natural reserve characterized by Terra Firme soils richer in clay and organic matter. 

![](soil_euk_loc.png){width=50%}

At each site 16 samples were collected, with sample points separated from one another by 20 m arranged in a grid across a 1 ha plot. For each sampling point, two substrate types (soil and litter) were sampled. One soil sample corresponds to a composite sample of five soil cores. One litter sample corresponds to ca. 1 m2 of litter collected from the forest floor. A total of 64 DNA extracts were thus produced, in addition to four DNA extraction controls (one per site and compartment).
 
For each DNA extract, a short region of the 18S rRNA (Taberlet, Bonin, Zinger, & Coissac, 2018) was amplified by PCR in quadruplicate, following the protocol described in (Zinger et al., 2019). The resulting amplicons were pooled and sequenced on an Illumina HiSeq platform, using paired-end technology.
 
The total experiment hence resulted in 384 amplicons as follows:

- 4 PCR replicates / sample (n = 256)
- 4 PCR replicates for the 4 extraction controls (n = 16)
- 4 PCR replicates for 8 PCR controls (n = 32)
- 4 PCR replicates for 12 sequencing controls (n = 48)
- 4 PCR replicates for 8 positive controls (plant DNA from 16 species; n = 32)

The retrieved data were then processed using the OBITools (Boyer et al., 2016) and SUMACLUST (Mercier et al. 2013) packages. Briefly, paired-end reads were assembled, assigned to their respective samples/marker and dereplicated. Low-quality sequences (containing Ns, shorter than 50 bp or singletons) were excluded. The remaining sequences were clustered into molecular operational taxonomic units (MOTUs) using SUMACLUST at a sequence similarity threshold of 0.97. The representative sequence of each motu (i.e. the most abundant sequence) was assigned a taxonomic clade using a database built from the EMBL (release 136) with the ecoPCR program (Ficetola et al., 2010).

<span style="color:red">not sure here that we need to explain everything, this is just a copy paste from the help page, we might need to lighten this document a bit</span>

This description can also be found in the `soil_euk` help page: 

```{r help}
?soil_euk
```

The example dataset is loaded in R as follows: 

```{r soil_euk_data}
data(soil_euk) 
summary_metabarlist(soil_euk)
```

This reveals dataset characteristics which correspond to those mentionned above: 12647 eukaryote MOTUs from 384 PCR amplifications, corresponding to 64 soil cores. In addition, this dataset contains some information relative to MOTUs (15 characteristics), PCRs (11), and samples (8).   

This information can be observed with basic R commands, given that the `metabarlist` object is an R `list`:  

```{r namesex}
colnames(soil_euk$pcrs)
colnames(soil_euk$samples)
```


## Example analysis with the `soil_euk` dataset

### Data import

*MetabaR-F* provides import tools for different data formats. Let's consider for example a suite of four basic .txt files each corresponding to the future `reads`, `motus`, `pcrs`, and `samples` objects. These can be imported and formated into a `metabarlist` as follows: 

```{r import, eval=F}
soil_euk = tabfiles_to_metabarlist(file_reads = "litiere_euk_reads.txt",
                                   file_motus = "litiere_euk_motus.txt",
                                   file_pcrs = "litiere_euk_pcrs.txt",
                                   file_samples = "litiere_euk_samples.txt")
```

### Diagnostic Plots

Before proceeding with data processing, it is useful to begin with an initial vizualization of the raw data, which can highlight any potential problems. 

For example, one would consider determining how many reads and MOTUs are obtained across the different control types. To do so, one would first need to store the total number of reads and MOTUs for each PCR in `pcrs`...

```{r}
soil_euk$pcrs$nb_reads = rowSums(soil_euk$reads)
soil_euk$pcrs$nb_motus = rowSums(soil_euk$reads>0)
```

... and then plot the results using the "control_type" column of the `pcrs` table

```{r boxplotreads_raw, warning=F, message=F, cache = T, fig.width=7}
library(ggplot2)
library(reshape2)

#create an input table (named check1) for ggplot: 3 columns: (i) control type, (i) aggregated nb_reads and nb_motus, (iii) and their corresponding values
check1 = melt(soil_euk$pcrs[,c("control_type", "nb_reads", "nb_motus")])

ggplot(data = check1, aes(x=control_type, y=value, color=control_type)) + 
  geom_boxplot() + theme_bw() + 
  scale_color_manual(values = c("brown", "red", "cyan4","pink"), na.value = "darkgrey") +
  facet_wrap(~variable, scales = "free_y") + 
  theme(axis.text.x = element_text(angle=45, h=1))
```

Although we would hope / expect to find no or only few reads in extraction and PCR negative controls, this is not the case here (remember that the `NA` in control_type correspond to PCRs from biological samples). No worries for now, it's quite common for this not to be the case in DNA metabarcoding datasets.   

Another way to vizualise this is from the perspective of its PCR design context, e.g. by showing the number of reads in the PCR plates, if this information has been recorded in the `pcrs` file. This vizualisation can highlight potential issues which may have occured during the PCR stage of sample processing. For example, low read abundances in real samples throughout one line or column of the PCR plate could mean that a primer was dysfunctional or that the mix deposition was inconsistent, resulting in low amplicon yields. Let's see how it appears for the `soil_euk` data:   


```{r ggpcrplate, warning=F, message=F, cache=T, fig.width=7, fig.height=5}
ggpcrplate(soil_euk, 
           FUN = function(m){
             rowSums(m$reads)
           },
           legend_title = "# of reads per PCR")
```

The above commandline shows how the number of reads per PCR can be represented using `ggpcrplate`. This operation is the default when using this function, and can be obtained with the basic call as below.

```{r ggpcrplate2, warning=F, message=F, cache=T, fig.width=7, fig.height=5, eval=F}
ggpcrplate(soil_euk)
```

In addition to patterns of general interest, the plot above shows two key features:    

- Sequencing negative controls (i.e. wells where no PCR amplification was conducted) have low or null read numbers. This means that "tag-jumps" <span style="color:red">ref</span> are relatively limited in this experiment.   

- The wells in plate 1, line H, exhibit a low number of reads. This tendancy might denote a problem, as mentionned above.  


If the user has defined the PCR design using a combination of tags (i.e. 2 different tags in the 5' of each PCR primer), and that this information is available in the `pcrs` table, it is possible to determine if one of the tag introduced some biases in PCR amplicon yields with the ggpcrtag function : 


```{r ggpcrtag, warning=F, message=F, cache=T, fig.width=7, fig.height=7}
ggpcrtag(soil_euk, legend_title = "# of reads per PCR",
                     FUN = function(m) {
                       rowSums(m$reads)
                     },
                     taglist = as.character(unique(soil_euk$pcrs$tag_rev))) 
```

This is also called with the base fuction 

```{r ggpcrplate3, warning=F, message=F, cache=T, fig.width=7, fig.height=5, eval=F}
ggpcrtag(soil_euk)
```

This plot shows the number of reads in their full PCR design. The Boxplots above and to the right show the distribution of the number of reads obtained for each tag-primer. Although the central plot obtained with `ggpcrtag` is equivalent to the one produced with `ggpcrplate`, this kind of plot can prove useful when looking for tags which may yield low read numbers in larger scale experiments.

Another useful tool to determine PCR success is the production of rarefaction curves, which will indicate whether the diversity of each PCR amplification is well covered by sequencing. 

In *MetabaR-F* this analysis is done for different diversity indices, and not only for richness. These indices correspond to Hill numbers where $q=\left\{0,1,2\right\}$ (Chao, Chiu, & Jost, 2014). These are equivalent to richness ($q=0$), the exponential of the Shannon index ($q\to1$), and the inverse of the Simpson index ($q=2$). The rationale for calculating these different indices is to give more or less weight to rare species, since these may correspond to molecular artifacts.

The function also returns Good's coverage index ($G=1-\frac{n_{singletons}}{N}$, where $n_{singletons}$ is the number of singletons, and $N$ is the total number of reads. Note that this latter index should be interpreted carefully, as it is based on singletons in each amplicon, some of which will have already been filtered during the bioinformatic process (filtering of absolute singletons).

Since this analysis can take a while in R, we will only conduct it on a subset of PCRs (in this case by keeping only samples from the H20 plot of the Petit Plateau). This subsetting can be done as follows:  

```{r subset, message=F, warning=F, cache=T}
#get the samples names from the H20 plot
h20_id = rownames(soil_euk$pcrs)[grep("H20-[A-B]", rownames(soil_euk$pcrs))]

#subsetting the data
soil_euk_h20 = subset_metabarlist(soil_euk, table = "pcrs", indices = h20_id)

summary_metabarlist(soil_euk_h20)
```

Note that subsetting can be done using any criterion (i.e. based on MOTUs, PCRs, or sample characteristics).  

Now lets conduct the rarefaction analysis. The diversity value is estimated through a certain number of data rarefactions (defined by the `nboot` argument), at each sequencing depth (defined by the `nsteps` argument, which correspond to the number of sequencing depth levels used for analysis). The `nboot` is low here to limit the computing time. It should be higher (e.g. nboot = 100) although this depends on sample or pcr diversity.

```{r hillraref, message=F, warning=F, cache=T}
soil_euk_h20.raref = hill_rarefaction(soil_euk_h20, nboot = 20, nsteps = 10)
head(soil_euk_h20.raref$hill_table)
```

The `hill_rarefaction` function produces an object from which the first element is a table indicating the pcr_id, the sequencing depth at which the PCR was resampled, and the corresponding pool of diversity / coverage indices. These can now be used to draw rarefaction curves.

```{r gghill, message=F, warning=F, cache=T, fig.width=7, fig.height=2}
gghill_rarefaction(soil_euk_h20.raref)
```

You may also need to differenciate different types of samples, for example soil vs. litter samples (information which stored in the "Material" column of the `samples` table). This can be achieved as follows:  

```{r gghill2, message=F, warning=F, cache=T, fig.width=7, fig.height=2.5}
#define a vector containing the Material info for each pcrs designated by their pcr names
material = soil_euk_h20$samples$Material[match(soil_euk_h20$pcrs$sample_id,
                                               rownames(soil_euk_h20$samples))]
material = setNames(material,rownames(soil_euk_h20$pcrs))

#plot
p = gghill_rarefaction(soil_euk_h20.raref, group=material)
p + scale_fill_manual(values = c("goldenrod4", "brown4", "grey")) +
    scale_color_manual(values = c("goldenrod4", "brown4", "grey")) +
    labs(color="Material type")
```

The generated curves tell us a couple of things about our samples:

 - The less we take rare species into account (increasing the hill number), the quicker that our curves reach saturation.    
 - Litter samples in general tend to be less diverse than soil samples    
 - The PCRs do not contain the same number of reads, although this is a normal feature of DNA metabarcoding data.    
 - The coverage plot suggests that the diversity is adequately sampled, given they all plateau at close to 1.    

<span style="color:red">###MOVE#####</span>.

A final vizualization consists in determining how the number of MOTUs and reads correlate. This information can help identify the sequencing depth below which a PCR might not be reliable.     

```{r readsMOTUs, message=F, warning=F, cache=T, fig.width=6, fig.height=3, eval = F}
library(vegan)
#First, calculate the number of reads and MOTUs per sample
soil_euk$pcrs$nb_reads = rowSums(soil_euk$reads)
soil_euk$pcrs$nb_motus = specnumber(soil_euk$reads)

#Now plot these values against one another
ggplot(soil_euk$pcrs, aes(x=nb_reads, y=nb_motus, color = control_type)) + 
  geom_point() + theme_bw() + 
  scale_y_log10() + scale_x_log10() + 
  scale_color_manual(values = c("brown", "red", "cyan4","pink"), na.value = "darkgrey")
```

<span style="color:red">We need to explain why. And I wonder actually whether this plot should not be done at the end, to define the threshold below which one consider a PCR as dysfunctional.

The more that the number of reads correlates with the number of motus the more likely that the dataset contains errors.... 

In general, the plot demonstrates a consistent overall positive correlation between the number of reads a sample may contain and the number of MOTUs these represent. The number of reads and MOTUs is highest for true sample pcrs, putting these up in the top-right hand corner of the plot, with positive, extraction and pcr controls also containing a high number of reads and a lower but nevertheless important number of MOTUs. </span>.

<span style="color:red">###MOVE#####</span>.

The next steps in this tutorial will be use the inforation provided by these controls to remove any potential contaminants or spurious sequences from our true sample pools.

### Contaslayer

During PCR amplification, contaminants can result in the presence of sequences which do not come from your biological samples. Contamination can occur at multiple stages, firstly during DNA extraction, during PCR amplification and even later during sequencing. Detecting these contaminants can be done through the use of control samples at each stage, as is the case for our example dataset. 

In negative controls, a contaminant should be preferentially amplified since there is no competing DNA. The function contaslayer relies on this assumption and detects OTUs whose relative abundance across the whole dataset is maximum in negative controls. The contaslayer function produces a vector of motu or sequence names, that can be used to tag those sequences within the  soil_euk metabarlist, making their removal possible at subsequent stages.

```{r contaslayer, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Define a vector containing the control names

pcr.controls = rownames(soil_euk$pcrs)[which(soil_euk$pcrs$control_type=="pcr")]

#now detect contaminants within your metabarlist
contaminant_PCR = contaslayer(soil_euk, controls = pcr.controls)

#tag these sequences in the metabarlist object
soil_euk$motus$flagged_motus = NA
soil_euk$motus[contaminant_PCR, "flagged_motus"]  = "contaminant"
```

To illustrate this apporach, below are the ten most common contaminants identified by contaslayer in our dataset.

```{r contaslayer2, message=F, warning=F, cache=T, echo=F, fig.width=6, fig.height=3}
library(kableExtra)
dt = soil_euk$motus[!is.na(soil_euk$motus$flagged_motus), c("count", "best_identity.order_filtered_embl_r136_noenv_EUK", "path")]

colnames(dt) = c("# reads", "% similarity to ref", "full taxonomic path")

kable(dt[order(dt[,1],decreasing = TRUE)[1:10],]) %>%
  kable_styling(bootstrap_options= c("striped", "hover", "condensed"), 
                font_size = 8)
```


The identified contaminants correspond to metazoans (including humans), protists, fungi and plants. The most abundant contaminant does not have precise taxonomic identification here, but a BLAST of the sequence revealed it to be a Fusarium, a notorius laboratory contaminant.

Next, we may want to know where these contamiants are present and if they are widespread across our experiment. This can be achieved using the ggpcrplate function introduced earlier. Let's take a look at the occurence of our most common contaminant.

```{r contaslayer3, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Identify the most common contaminant
max.conta = contaminant_PCR[which.max(soil_euk$motus[contaminant_PCR, "count"])]

#Distribution of the most abundant contaminant in the PCR plate design
ggpcrplate(soil_euk,
   legend_title = "#reads of most \nabundant contaminant",
   FUN = function(m) {
     m$reads[, max.conta]})
```

In this case, the most abundant contaminant is most prevalent in the pcr controls, but it appears across all samples. 

This can also be represented in the form of a box plot.


```{r contaslayer4, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#First determine the proportions total reads corresponding to contaminants

a <- decostand(soil_euk$reads, "total")
a <- a[,!is.na(soil_euk$motus$flagged_motus)]

#plot the results
b <- melt(a)
b$control_type <- as.vector(soil_euk$pcrs[b$Var1,"control_type"])  
b$control_type[is.na(b$control_type)] = "sample"
b$control_type <- factor(b$control_type, levels=c("extraction", "pcr", "sequencing", "positive", "sample"))

ggplot(data = b, aes(x=control_type, y=value, color=control_type)) + 
  geom_boxplot() + theme_bw() + 
  scale_color_manual(values = c("brown", "red", "pink","cyan4", "darkgrey")) +
  scale_y_log10()+
  theme(axis.text.x = element_text(angle=45, h=1))
```

We can see how contaminants are distributed across our experiment. We can alsouse this plot to identify whether conamiants occur in our samples, and if so, whether we can consider certain pcrs as too contaminanted to be reliable, and therefore exclude them from the dataset. This is necessary here.


##Highly degraded or non-target MOTUs
In addition to contamiants, other non-target sequences can be amplified and sequenced. This includes non-target taxa, or sequences which are highly degraded such as primer polymers, or multiple chimeras. We can use the MOTU taxonomic information, in addition to their similarity against our taxonomic databse. 

For non-target taxa in our example dataset, we would not expect to find bacteria or archea.

```{r nontarget, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Find the motus table indices for non-target taxa

id <- grep("Bacteria|Archaea", soil_euk$motus$path)

length(id)
```

Here we find 7 MOTUS which have been identified as Bacteria or Archeaa. Since they are not of interest to us, we will tag these to remove them at a later stage.

```{r nontarget2, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#tag these sequences in the metabarlist object as non-target
soil_euk$motus$flagged_motus[id] = ifelse(is.na(soil_euk$motus$flagged_motus[id]),"non_target", paste(soil_euk$motus$flagged_motus[id], "|", "non_target", sep = ""))

#check
soil_euk$motus$flagged_motus[id]
```

In this case, you can see that three of our non-target sequences have previously been identified as contaminants. Here, we tag the sequences as non_target, but maintain the prior contaminant tag.

Next, we want to identify those MOTUS whose sequence is too dissimilar from our taxonomic databases to be considered a true sequence, but instead is more likely to be a degraded sequence. A threshold of similarity should be chosen which is representative of how complete the taxonomic database used is likley to be. In this case, we want to tag any sequence which is below 90% similar to our taxonomic database. 

```{r nontarget3, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Find the motus table indices for taxa with a similarity to taxonomic databases

id2 <- which(soil_euk$motus$best_identity.order_filtered_embl_r136_noenv_EUK<=0.9)
```

Here we have identified 4231 sequences which are less than 90% similar. These are tagged for removal at a later stage.

```{r nontarget4, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#tag these sequences in the metabarlist object as dissimilar
soil_euk$motus$flagged_motus[id2] = ifelse(is.na(soil_euk$motus$flagged_motus[id2]),"dissimilar", paste(soil_euk$motus$flagged_motus[id2], "|", "dissimilar", sep = ""))

#check
table(soil_euk$motus$flagged_motus)
```

##Tag-switching

Tagjumps are an important bias that lead to the presence of potentially high numbers of false positives in DNA metabarcoding data. The origin of this bias is not well known yet, although currently suspected to be generated during the PCR enrichment process of the sequencing library preparation. Incomplete PCR amplification at this stage may lead to the formation of chimeras at priming sites, from fragments belonging to two different amplicons. The resulting fragment is therefore strictly identical to the genuine OTU, but its tag combination is artifactual. This bias is also frequency-dependant, i.e. abundant genuine OTUs are more likely to be found in low abundance in samples were they are not supposed to be. The function aims at reducing the amount of such false positives, by considering each OTU separately and setting to 0 any abundance representing < 0.03% of the total OTU abundance in the entire dataset. <span style="color:red"> Why <0.03% ? </span>.

Let's compare the presence of the most abundant MOTU before and after applying the threshold, to see how it changes the overall pattern of occurence across the experiment.

```{r tagjump, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Distribution of the most abundant contaminants in the PCR plate design

soil_euk_clean <- tagjumpslayer(soil_euk, 0.03)

#identify occurrence of the most abundant MOTU
idx <- which.max(soil_euk$motus$count)
p1 <- ggpcrplate(soil_euk,
legend_title = "# reads",
   FUN = function(m) {
     m$reads[, idx]
   }
 )
 p1 + scale_size(limits = c(1, max(soil_euk$reads[, idx]))) +
   ggtitle("Distribution of the most abundant OTU")

#same on clean data
p2 <- ggpcrplate(soil_euk_clean,
 legend_title = "# reads",
 FUN = function(m) {
   m$reads[, idx]   }
 )
 p2 + scale_size(limits = c(1, max(soil_euk_clean$reads[, idx]))) +
   ggtitle("Distribution of the most abundant OTU after curation")
```

These plots demonstrate that a large number of reads for the most abundant OTU were removed from certain PCRS, but that it is maintained in those PCRs where the number of reads was highest.

<span style="color:red"> Do we need to indicate that soil_euk_clean should be used from now on?? </span>.

#Dysfunctional PCRs

##PCRs with too low amounts of reads
PCR slayer

The pcrslayer function identifies potential non-functional PCR reactions by comparing the dissimilarities in OTU composition within a biological sample (i.e. between PCR replicates, hereafter dw) vs. between biological samples (hereafter db). It relies on the assumption that PCR replicates from a same biological samples should be more similar than two different biological samples (dw < db). More specifically, the function consists in first constructing an average OTU community for each biological sample by averaging the OTUs abundances of PCR replicates from the same biological sample. Dissimilarities dw are then defined as the pairwise Bray-Curtis dissimilarities between PCR replicates with their associated average OTU community. Dissimilarities db correspond to the pairwise Bray-Curtis dissimilarities between average OTU communites from the different biological samples. A PCR replicate having a dw above a given dissimilarity threshold (tresh) is considered to be too distant from its associated average OTU community and are excluded from the analysis. The whole process is repeated iteratively until no more PCR are excluded from the analysis. If only one single PCR replicate is representative of a biological sample after this trimming, it is also considered as a dysfunctional PCR.

The threshold (tresh) is defined automatically with two alternative methods. Either it is the intersection of dw and db distributions (tresh.method="interesect"). Or it is the mode of the db distribution (tresh.method="mode").

Function check_pcr_thresh enables visualization of dw and db distributions. Function check_pcr_repl enables visualization of PCR replicate dissimilarity patterns in a NMDS ordination and distance from their average OTU community.

Function pcr_control is another way of detecting dysfunctional PCRs, and considers that any PCR replicate that is too similar to any control amplicon (blank or mock community) is dysfunctional. Note that this function will not be appropriate if one or more controls are contaminated with the DNA from biological samples (e.g. cross-contaminations). ### TO FINISH


```{r pcrslayer, message=F, warning=F, cache=T, fig.width=6, fig.height=3, eval = F, eval = F}
# define replicate factor
# Consider only biological samples
sample_subset <- subset_metabarlist(soil_euk, "pcrs", rownames(soil_euk$pcrs)[which(soil_euk$pcrs$type == "sample")])

# first visualization
comp1 <- pcr_within_between(sample_subset$reads, replicates = sample_subset$pcrs$sample_id)
check_pcr_thresh(comp1, thresh.pcr = NULL)
# visualization of replicates through NMDS
nmds <- check_pcr_repl(sample_subset$reads,
replicates = sample_subset$pcrs$sample_id,
colvec = paste(sample_subset$samples$Habitat, sample_subset$samples$Material, sep = "|")
)
nmds + labs(fill = "sample type")

# identify dysfunctional PCRs
bad_pcrs <- pcrslayer(sample_subset,
  thresh.method = "intersect",
  replicates = sample_subset$pcrs$sample_id
 )

 nmds <- check_pcr_repl(sample_subset$reads,
   replicates = sample_subset$pcrs$sample_id,
   colvec = paste(sample_subset$samples$Habitat, sample_subset$samples$Material, sep = "|"),
   dyspcr = bad_pcrs
 )
 nmds + labs(fill = "sample type")
```


## References

Boyer, F., Mercier, C., Bonin, A., Le Bras, Y., Taberlet, P., & Coissac, E. (2016). obitools: a unix-inspired software package for DNA metabarcoding. Molecular Ecology Resources, 16(1), 176???182.

Chao, A., Chiu, C.-H., & Jost, L. (2014). Unifying Species Diversity, Phylogenetic Diversity, Functional Diversity, and Related Similarity and Differentiation Measures Through Hill Numbers. Annual Review of Ecology, Evolution, and Systematics. https://doi.org/10.1146/annurev-ecolsys-120213-091540

Edgar, R. (2018). UNCROSS2: identification of cross-talk in 16S rRNA OTU tables. https://doi.org/10.1101/400762

Ficetola, G. F., Coissac, E., Zundel, S., Riaz, T., Shehzad, W., Bessi??re, J., ??? Pompanon, F. (2010). An in silico approach for the evaluation of DNA barcodes. BMC Genomics, 11, 434.

Taberlet, P., Bonin, A., Zinger, L., & Coissac, E. (2018). Environmental DNA. Oxford Scholarship Online. https://doi.org/10.1093/oso/9780198767220.001.0001

Zinger, L., Taberlet, P., Schimann, H., Bonin, A., Boyer, F., De Barba, M., ... Chave, J. (2019). Body size determines soil community assembly in a tropical forest. Molecular Ecology, 28(3), 528???543.

